
  Since the early days of video technology, one of the problems that raised with it consisted of how to add more information onto it without generating multiple versions. Some implementations like \cite{embedded} added hypermedia information to empty space present on \ac{MPEG} frames in order to provide interactive television, the \ac{MPEG} coder and decoder were changed in order to handle hypermedia content.

  The need to translate movies, raised the problem whether it is apropriate to change the original video or audio. For example subtitles should be an entity independent from the video, in order to be personalized or replaced easily.
 
  Amongst multiple formats for subtitles, \ac{SAMI}, and \ac{SRT} are used by video players that support them. Although those formats have styling available, they are quite limited to text. 

  Hypervideo is a kind of video that contains links to any kind of hypermedia, including links to skip part of it. An example of hypermedia application could be a search engine over hypermedia content, like subtitles, in order to jump to a specific point in time. HyperCafe \cite{hypercafe} was an experimental project to expose hypervideo concepts that consisted on an interactive film by switching between conversations inside a cafe.

  Detail-on-demand is a subset o hypervideo that allow us to obtain aditional information about something that apears along the video, like obtaining information about a painting that appears in a particular segment. Hyper-Hitchcock\cite{hitchcock} is an editor and player of detail-on-demand video.

  In order to navigate through a dynamic video, one must be aware of time synchronization and the multiple time flows, it's important that all time, causality and behavior rules are well defined.
 
  HyVAL\cite{hyval} is an \ac{XML} based language that was proposed for modeling composition, synchronization and interaction of hypermedia. HyVAL defines defines video structure, internal video and external media objects. 

  HyVAL video structure objects defines a structure derived from traditional video, which divides video into segments, scenes, shots and frames hierarchically, this approach is quite limitative if we want to apply hypervideo concepts to videos that don't follow this structure. External media objects are linked by primary video, those objects can represent other videos, images, text, animation and sound.

  \ac{SMIL}\cite{smil} was introduced to describe temporal behavior of multimedia content, in particular, it could be used to overlay subtitles on films. With \ac{SMIL} it's possible to synchronize multiple sections of video, either in parallel or in sequence, reproduce a different audio track, overlay user interface elements with hyperlinks, amongst multiple other functionalities.

  \ac{SMIL} is \ac{XML} based and defines twelve modules: \textit{Animation}, \textit{Content Control}, \textit{Layout}, \textit{Linking}, \textit{Media Objects}, \textit{SmilText}, \textit{Metainformation}, \textit{Structure}, \textit{Timing}, \textit{Time Manipulations}, \textit{State} and \textit{Transitions}.

\begin{itemize}

  \item \textbf{Animation} module contains elements and attributes that define a time based mechanism for composing the effects of animations. For example, this module can changes on \ac{XML} or \ac{CSS} attributes like colour and dimensions.  

  \item \textbf{Content Control} module contains elements and attributes that provide optimized alternatives for content delivery. For example, it could be used to change audio language in function of user's nationality, for videos with multiple audio channels.

  \item \textbf{Layout} module contains elements and attributes for colouring and positioning media content, another layout mechanisms are also possible, such as \ac{CSS}.

  \item \textbf{Linking} module contains elements and attributes for navigatonal hyperlinking. Navigation can be triggered by events or user interaction.

  \item \textbf{Media Object} module contains elements and attributes for referencing rendering behaviour of external multimedia or control objects.

  \item \textbf{SmilText} module contains elements and attributes that defines and controls timed text. For example this module could be used to create labels and captions.

  \item \textbf{Metainformation} module contains elements and attributes that allows describing the \ac{SMIL} document. For example, this module could be used to define a movie details such as category, director, writters and cast.

  \item \textbf{Structure} module defines the basic elements and attributes for structuring \ac{SMIL} content. This module defines a \textit{head} element that contains non temporal behaviour information defined by  \textit{Metainformation}, \textit{Layout} and \textit{Content Control} modules. This module also defines defines the \textit{body} element, where all temporal related module information is contained.

  \item \textbf{Timing} module is the most important module on \ac{SMIL} specification, because of its complexity, it is divided into seventeen submodules for coordination and synchroniztion of media over time. The three main elements are \textit{seq}, \textit{excl} and \textit{par}, respectively, they play child elements in sequence, one at a time and all at the same time. 

  \item \textbf{Time Manipulations} module adds time behaviour attributes to \ac{SMIL} elements, such as speed, rate or time.

  \item \textbf{State} module defines attributes that defines the state of \ac{SMIL} elements, such as element visibility, current element time, amount of repeated loops, playing state and many others.

  \item \textbf{Transitions} module defines attributes and elements that defines transitions across multiple \ac{SMIL} elements according to \textit{Timing} module.

\end{itemize}

The \ac{DOM} is a standard \ac{API} that allows easy management of documents that are organized in a tree structure, by providing \ac{CRUD} operations over its elements and their attributes. \ac{DOM} makes it easy to interoperate between imperative and declarative programming languages.
  
Like \ac{DOM}, \ac{SMIL} \ac{DOM} is an \ac{API} for \ac{SMIL} documents. Allowing \ac{CRUD} operations over \ac{SMIL} documents is an important feature for extending \ac{SMIL} capabilities, for example for creating non-linear animations and triggering external events like \textit{javascript} functions.  

  \ac{SMIL}'s modules are used to synchronize and animate \ac{XHTML} and \ac{SVG} elements.

  In order to create a multimedia rich hypercall, \ac{SMIL} fits our goals, but it lacks on browser compatibility. Ambulant \cite{ambulant} was one of the SMIL players that were developed for browsers, although this player implements most of \ac{SMIL} 3.0 \cite{smil3} specifications, it needs to be installed on browsers as a plugin.

{\color{red} [more on smilling web would be nice]}

  SmillingWeb \cite{smillingweb} attempts to implement \ac{SMIL} 3.0 cross platform video player with javascript and jQuery, which doesn't need to be installed and shouldn't have incompatibility issues. But SmillingWeb isn't fully implemented yet and their scheduler engine loads the \ac{SMIL} file only once, which could raise problems when leading with \ac{SMIL} changes in real time.  

  \ac{SVG} is an \ac{XML} based format that incorporates the animation module of \ac{SMIL}. Currently \ac{SVG} allows to add movement and animate attributes of elements. When embedded on \ac{HTML}, it allows dynamic changes to inner content in real time through \ac{DOM} \ac{API}, besides that, it also allows to call javascript functions on events such as animation end, mouse over and mouse click.

{\color{red} [svg is more than this]}

  Video functionalities are already embedded in \ac{HTML}5, like \ac{SVG} it is also possible to bind javascript functions for different kinds of events over videos.

  Back in 1995, \textit{flash}\footnote{\url{flash site}} was developed for web-based animations, introducing video support in 2002, flash started to grow after that. Concurrency players, at that time, were focused on playing video and audio, flash had vector graphics and they were focused on streaming \textit{on-demand} video across multiple platforms. VP6 was their choice on video codecs, optimizing for half of video size for the same quality and providing adjusted video quality based on internet connection latency. 

  Adobe Flash was the most widely used applications for reproducing live broadcast and recorded video \cite{flashvideo}, it supports progressive video download using \ac{HTTP} and streaming using \ac{RTMP}. 

  \ac{RTMP} is a \ac{TCP} based protocol used to streaming audio, video and data between \ac{FMS} and flash player. A bidirectional connection is established between the two to in order allow real time coomunications. A flash player can stream a webcam video to \ac{FMS} according to \ac{RTMP} and another flash player can request a video stream to \ac{FMS} that can be pre-recorded stream, live stream or data. Multiple \ac{FMS} servers can be chained together in order to increase capacity and handle more streams simultaneosly.

  \ac{FMS} can stream video and audio to one or more subscribers by sending a separate copy for each subscriber. With \ac{RTMFP} is possbile to stream video between flash players, allowing a publisher breaking a stream into pieces that can be cooperatively distributed in a P2P mesh, \ac{RTMFP} uses \ac{UDP} to speed packet delivery, although is not reliable, it is well suited for video streaming, like \ac{WebRTC} flash players also need to apply techninques like \ac{STUN} and \ac{TURN} for \ac{NAT} traversal.

  Although \ac{HTML}5, javascript, \ac{CSS} and \ac{WebRTC} are implementing some functionalities of flash, it doesn't mean that flash will be replaced, instead of that both technologies can used to develop rich internet applications. It is also important to note that \ac{HTML}5 is more compatible with mobile devices than adobe flash.

  Like Flash, Microsoft Silverlight is a cross browser plugin and platform that is used to develop rich internet applications. It supports vector graphics, animation and video. Compared to flash, which uses ActionScript, Silverlight applications can use languages like C\#, VisualBasic and \ac{XAML}. Silverlight uses a technique called Smooth Streaming from IIS Media Service that consists on delivering video in real time with adjusted quality in function of bandwidth changing and \ac{CPU} usage.



  By using techonologies that relies only on web standards, like \ac{CSS}, \ac{HTML}5, Javascript and \ac{SVG}, it's possible to raise communications to a new level. For example, with \ac{API}s like WebGL\footnote{\url{http://khronos.org/webgl/}}, it is now possible to manipulate a three dimensional environment in the context of a hypercall. Another example would be a collaborative spreadsheet using WebRTC. With this, hypercalls are not limited to only audio, image, text and video, but also interaction with complex graphical user interfaces that changes over time.

  In this project our goal is to enrich hypercalls with no limits, every user should be free to choose how it wants to be contacted and it wants to share its contents.

  In order to give users a personalized communication channel, each user must have a personal web page where its available plugins could be downloaded from other peers, after that they can talk in the same language whatever it is.
