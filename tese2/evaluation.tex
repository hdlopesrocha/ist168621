\chapter{Evaluation}
\label{chapter:evaluation}
  In the previous chapter we described how we implemented our solution namely the data model that we used, the description of the signaling protocol, how we performed stream recording, how we overlayed interactive content to video and lastly how we deployed our solution. 

  In this chapter we describe how we tested our solution, show and analyse the results in order to validate the contributions of this thesis.

\section{Tests Objectives}

  We have tested our solution with real users for a better understanding of their difficulties and what can be done in order to improve our solution's usability.

  We have also tested the performance of our solution by measuring the used resources. Those performance tests are crucial to ensure that our solution is in fact stable and users can use it timelessly without decreasing the quality of their experience. 


\section{Tests Scenarios}

  In this section we describe both performance and usability test scenarios that we have applied.

  \subsection {Performance Tests}
      In order to benchmark our system, we have implemented a small \emph{Python} script using \emph{psutil}\footnote{\url{https://github.com/giampaolo/psutil} (Accessed March 27, 2016)} that collects with a periodicity of one second; CPU, physical memory information realtive to each running process and network usage relative to each interface. 

      We would like to collect network information relative to each process, which \emph{nethogs}\footnote{\url{https://raboof.github.io/nethogs/} (Accessed March 27, 2016)} provide but it could not capture the network usage of some processes. Although this would be useful for a deep analysis, we know which network interfaces are used to establish connections between processes as we show on table \ref{table:interfacemap}.

  \begin{table}[H]
\centering
\caption{Mapping of connections by network interface}
\label{table:interfacemap}
\begin{tabular}{|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{Interface}} & \multicolumn{1}{c|}{\textbf{Connection}}         \\ \hline
Loopback & Web Server $\leftrightarrow$ MongoDB  \\ \hline
Loopback & Web Server $\leftrightarrow$ Kurento Media Server  \\ \hline
Loopback & Kurento Media Server $\leftrightarrow$ Kurento Repository $\leftrightarrow$ MongoDB  \\ \hline
Ethernet & Web Server $\leftrightarrow$ Client\\ \hline
Ethernet & Kurento Media Server $\leftrightarrow$ Client\\ \hline
\end{tabular}
\end{table}


      The performance test scenario that we have defined consists on two phases, the first phase consists only on having users, with similar computer and network specifications, entering sequentially on the conference room, the second phase consists on the users leaving the conference room. Each event, joining and leaving, occurs with intervals of one minute in total of thirteen minutes (780 seconds).

  \subsection {Usability Tests}

      In order to the usability of our solution, we haver performed usability tests with the help of real users with different backgrounds and ages.

      We handled a guide to the users with five tasks to perform, the metrics we used for each task were: number of clicks, number of errors including a description and time spent. 

      The tasks we asked to the user are:

      \begin{enumerate}
      \item Login into the system with the provided credentials and accept the received friendship request. Find the coordinator's brother and add him as a friend.

      \item Create a private conference room, enter and share your screen, add the coordinator to the conference room and chat with him. After that use the collaborative editor in order to write at the same time as the coordinator. Lastly save the editor and leave the conference room.

      \item Enter in the conference room correspondent to the third task as an observer and navigate to the specified annotation. Watch the video until a list of topics is overlayed in the video and choose one of them and leave the conference room.

      \item Enter in the conference room correspondent to the fourth task by sharing your camera and create a time annotaion in the instant of time when you entered, navigate to the current time, search for the annotation and leave the conference room.

      \item Enter in the conference room correspondent to the fourth task by sharing your camera and add a subtitle in the video, preview it, specify an interval of time and save it. Then show the provided \emph{QR code} to the camera and leave the leave the conference room.
      \end{enumerate}

      The goal of the first task consists on evaluating the interface for authentication and friendship management.

      The second task is used to make the users familiar with our tools for collaborative content edition.

      The goal of the third task is to demonstrate the navigation functionalities and synchronized interactive content superposition.

      The fourth task is used to analyse the behaviour and difficulties of the user when creating a time annotation.

      The goal of the fifth task is to create synchronized overlayed content, demonstrate the difficulties of such task and present an easier way to synchronize content.


\section{Test Results}
  \subsection {Performance Tests}
  
      We are presenting in this sections the results of our performance tests after implementing our solution.

      Every time a user shares its camera or its screen in the context of a conference room, its offered video is sent to the server and independently from watching an individual stream or the mixed version the server just sends a unique stream back to the user.

      From the media server prespective if there are $n$ clients connected each of them sending and receiving one stream, it is expected that server sends and receives also $n$ streams. By so we expect that the amount of network increases lineraly as users join a confrence room.

      Figure \ref{fig:test_full_features_net} confirms our expectations, each vertical yellow line represents each event, the first seven events are users entering the conference room the next ones represent users leaving the conversation. 
      


\begin{figure}[H]
  \begin{center}
    \input{stats/test_full_features_net.tex}
  \end{center}
  \caption{Network usage after implementing all features}
  \label{fig:test_full_features_net}
\end{figure}

      The blue peaks are caused by the signaling phase and web page downloads, including resources such as images, stylesheets and javascript files. 
      The green peaks are caused by that being transfered between \ac{KMS} and \emph{MongoDB} through \emph{Kurento Repository} each peak occurs each time a block of video is recorded which in this case is every ten seconds. 
      The recordings are synchronized so all user and mixed blocks starts and ends at the same time, that's why the amount of work done every ten seconds acumulates and because this is poerformed locally the maximum transfer rate is limited by the performance of the memory as buffers are writen to buffers then to disks. 
      Client's sent data transfer rate has no significant peaks as signaling information contains few information.

      Figure \ref{fig:summary_full_net} shows the average transmission rate per interval of consecutive events. 

\begin{figure}[H]
  \begin{center}
    \input{stats/summary_full_net.tex}
  \end{center}
  \caption{Average network usage per interval of events after implementing all features}
  \label{fig:summary_full_net}
\end{figure}

If we consider all streams equal and an incoming stream uses $x$KB/s, with $n$ incoming streams the rate of data received at \ac{KMS} is $nx$ and the expected rate of data transfered to \emph{Kurento Repo} using localhost is $(n+1)x$. Due to the data being transfered also from \emph{Kurento Repo} to \emph{MongoDB} via localhost, the expected total rate of data transfered through localhost is $2((n+1)x) = (2n+2)x$, which explains the reason for the average amount of data transfered through localhost being more than twice the average amount of data received from users.

With this results we conclude that if we want to scale our solution's storage using the \emph{MongoDB}'s cluster configuration, both \emph{Kurento Repository} and \emph{MongoDB} should be installed in the same machine because the loopback interface can handle bigger transfer rates than the remaining network interfaces. For the same reason another possible configuration for scaling the storage is to install both \emph{Kurento Repository} and \ac{KMS} on the same machine.

